\textbf{A previous version of this chapter was published in \citet{CharltonLaudan2020WebBasedVisualization}.}

\vspace{5mm}

Open-source and commercial tools are available for analyzing MATSim transport simulation results, but these tools are typically installable desktop software that supports professional analyst workflows. This research builds a new, entirely web-based open-source visualization platform for MATSim outputs. Initial experiments with many different web technologies lead to a client/server platform design which relies on back-end server processing for more CPU-intensive tasks, while leveraging the advanced user interface capabilities of modern browsers on the front-end. The initial platform is now operational and includes several aggregate-level visualizations including transit supply, emissions on a network link basis, and origin/destination flows. There is also a fully disaggregate traffic animation visualization. These visualizations are general enough to be useful for various projects. Continuing work is expected to make the visualizations more compelling and the platform more featureful for practitioners.

\hypertarget{mathub-introduction}{%
\section{Introduction}\label{introduction}}

MATSim is an open-source framework for implementing large-scale agent-based transport simulations (\cite{MATSimBook}). MATSim has been widely used for transportation research in academic settings for almost 20 years, and is now gaining momentum in real-world planning contexts as well.

There are many open-source and commercial tools available for analyzing MATSim results. Analysts often choose either the free tool OTFVis (\cite{Srippgen2015OTFVisInBook}) or the commercial software Via (\cite{Rieser2015SenozonViaInBook}), both of which are desktop software packages that require installation as well as a fair amount of technical acumen to operate. General-purpose desktop mapping software packages such as QGIS\footnote{QGIS available at \url{https://qgis.org}} and ESRI ArcGIS\footnote{ESRI ArcGIS available from \url{https://www.esri.com}} are also good alternatives, as are professional statistical software packages including the R language... again all of which require installation and expertise to use.

A notable gap is apparent in the software ecosystem: there are scarce web-based interactive tools available for disseminating MATSim data and results, and none that are specifically targeting MATSim. As MATSim moves from the confines of academic research to a more public-facing role, this creates a challenge for using MATSim in public policy settings: the only people who can meaningfully examine and explore results are those who have extensive technical knowledge and access to the specialized software and large datasets involved.

This research explores one possible approach to filling this gap: building an open, web-based data visualization platform that is specifically designed to complement MATSim.

\hypertarget{mathub-motivation}{%
\section{Motivation}\label{mathub-motivation}}

The last five years have brought rapid advancement of Internet browsing technologies that enable the web browser to do things much more ``application''-like than ever before: background processing, three-dimensional rendering using \gls{GPU} acceleration, offline support, and more. The combination of these technologies and their widespread, standardized implementations on every popular hardware type and operating system now makes the web a feature-rich and compelling platform.

The research question for MATSim is: could a web browser really be useful for exploring and delivering results when the datasets involved are so large? Answering this question is the primary motivation for this research. Essentially: has the web become powerful enough for MATSim?

Currently, analysis of MATSim outputs typically ends up in research reports, PDFs, video screen-recordings, and presentations. An online dashboard of results which a user could explore and manipulate would not only be more compelling due to its interactivity, but might also reveal findings that the original analysts had not anticipated.

\hypertarget{mathub-requirements}{%
\section{Requirements}\label{requirements}}

The research team at Technische Universit√§t Berlin had several ``blank slate'' discussions before any code was written: meaning, if one could start at the very beginning and design something completely web-based and open, what would be the bare minimum requirements for it to be truly useful? The following list of requirements emerged from those discussions.

\hypertarget{requirement-1-web-browser-based}{%
\subsection{Requirement 1: Web browser-based}\label{requirement-1-web-browser-based}}

Given the above-stated motivation and hypothesis that the modern web platform is ready for large-scale visualization tasks, the most obvious requirement is that the product of this research must work with any modern web browser.

Web technologies developed and made widely available in recent years enable us to perform this research. These are the backbones of the modern web: HTML 5, CSS 3, WebGL, ECMA Script 6, and Web Workers. Briefly, these technologies are:

\begin{itemize}
\tightlist
\item
  \textbf{HTML 5} improves and standardizes what constitutes a web page and how it is specified in the ``document model'' of a web page.
\item
  \textbf{CSS 3} is a formatting and styling language that enables defining fine-grained layout and hierarchical styling of individual elements on a page. CSS 3 defines the details of elements including color, size, layout, and animation of page elements in a standardized way.
\item
  \textbf{WebGL} provides 3D-accelerated graphics capabilities to the browsers on modern machines, typically taking advantage of \gls{GPU} hardware processing.
\item
  \textbf{ECMAScript 6} is a modern (as of 2015) version of the original
  JavaScript scripting language that has been part of the web platform
  since the mid-1990's. ECMAScript 6 employs a ``strict mode'' that eliminates the
  more problematic aspects of older JavaScript versions, making it easier for
  developers to create bug-free, efficient code.
\item
  \textbf{Web Workers} allow background thread processing for long-running tasks. Before
  Web Workers were introduced in 2013, there was no standardized way to run truly multi-threaded code inside a browser.
\end{itemize}

A complication unique to web development is that the primary web browser vendors (Google, Apple, Mozilla, Microsoft) implement these ``standard'' technologies on their own timelines, some much more accurately and rapidly than others. End users also do not always upgrade their browsers frequently (or at all), further complicating matters. This defines a browser landscape where there is a technology adoption curve with a very long ``tail''. Developers of every web site need to make a conscious decision about where to draw the line when adopting the latest standards -- choosing necessary technologies for their site to operate correctly, while knowing that some users with older browsers might have a suboptimal experience or perhaps have a broken experience.

Despite these complications, this research deliberately chooses to explore the latest \emph{standard web technologies}, with the expectation that these standards will naturally become more and more common in the future. Thus, it targets the most recent versions of modern web browsers as of 2022, including Google Chrome, Mozilla Firefox, and Apple Safari. All three browsers fully support the above-listed technologies, and importantly, all three auto-update automatically. This ensures that most users of those browsers get the benefit of new features as these technologies mature.

\hypertarget{requirement-2-open-source}{%
\subsection{Requirement 2: Open
source}\label{requirement-2-open-source}}

The entire project, including all front-end (browser) and back-end (server) code, must be fully open source.

The goal of this research is not to replace existing, proprietary solutions, but rather to complement them. No proprietary or closed licensing schemes are considered, primarily because excellent proprietary visualization packages for MATSim already exist. Creating a competing commercial product would be duplicative and unnecessary, and would not further the research goal of determining whether \emph{open web-based technology} is now advanced enough to handle MATSim outputs.

The software developed as part of this research is licensed entirely with the GNU General Public License v3, commonly known as the ``GPL''\footnote{GNU General Public License (June 29, 2007). Version 3. Free Software Foundation. Available at \url{https://www.gnu.org/licenses/gpl.html}}

This matches the license of MATSim itself. Several other open-source licenses were considered, including the MIT License and the Apache Public License. The benefit of sharing a common license with MATSim likely outweighs any perceived benefits of switching to other open licenses.

\hypertarget{requirement-3-use-good-defaults-with-minimal-configuration-and-be-opinionated}{%
\subsection{Requirement 3: Use good defaults, with minimal configuration, and be opinionated}\label{requirement-3-use-good-defaults-with-minimal-configuration-and-be-opinionated}}

The web platform has focused on simplicity and smooth user onboarding since its original inception. Users expect to be immediately familiar with a site -- often within seconds of their first interaction. Because of this expectation, it is critical that this research follow current best practices for user interface (UI) and user experience (UX). Specifically, that means using familiar UI paradigms such as navigation bars and breadcrumbs, separating configuration from usage, limiting settings and options to the bare minimum, and being ``opinionated'', i.e.~encouraging a correct way to accomplish a task.

This approach is unlike some data exploration tools that MATSim analysts often use (e.g., QGis and Via) -- where extreme configurability is emphasized. This research focuses on choosing good defaults and determining whether that is sufficient for the software to be useful, rather than providing myriad options for details such as scales and color ramps,

\hypertarget{requirement-4-an-extensible-platform}{%
\subsection{Requirement 4: An extensible platform}\label{requirement-4-an-extensible-platform}}

There is no way to anticipate how end users will ultimately use the tool; every data visualization use case is different. If the platform is too generic, it will be not at all useful. Conversely, if only hard-coded visualizations are created for specific projects, it will be seen as a mere ``demo-ware'' product, meaning it is a successful technology demonstration but not actually useful for real users.

To fulfill this requirement, the software platform will need to be extensible: basic capabilities and templates can be provided, but a user with some level of coding skill should be able to create new visualizations, even those that are not anticipated by the researchers.

\hypertarget{mathub-initial-experiments}{%
\section{Initial experiments}\label{initial-experiments}}

The JavaScript code library ecosystem is extremely, enormously large. This is no exaggeration: tens of thousands of libraries and packages are available on the common centralized JavaScript repository known as \emph{NPM}, and there are often multiple packages that do similar or identical things. Of course these libraries are of varying levels of popularity and quality. As a developer, one must assess and select from these available packages or choose to solve a problem by writing code by hand.

Some initial experiments were carried out based on the requirements laid out above, in order to assess various approaches before committing to a technology stack.

\hypertarget{mathub-visualizing-time-dependent-data-on-a-geographic-map}{%
\subsection{Visualizing time-dependent data on a geographic
map}\label{visualizing-time-dependent-data-on-a-geographic-map}}

Two popular web-based JavaScript libraries were tested for displaying geographic data; Leaflet and Mapbox GL. A simple test case comprised of MATSim simulation outputs was developed, with the goal of displaying aggregated roadway link volumes by time of day.

Leaflet\footnote{Leaflet is available at \url{leafletjs.com}} is very popular and its application programming interface (API) is a bit simpler than that of Mapbox GL. Leaflet uses background map ``tiles'' at specific zoom levels, and layers data on top of those base maps. With small networks (for example Cottbus, Germany, was tested; a small city of 100,000 inhabitants), Leaflet performed well, but medium-sized and large-sized networks with many elements visible at once suffered from noticeable performance degradation. Even just panning and zooming a displayed map with a large network would ``jerk around'', with the display refreshing barely one frame per second -- well below what users expect. This was problematic, as this was the simplest use case envisioned.

Mapbox GL\footnote{MapBox GL is available at \url{www.mapbox.com}} fared much better, apparently better-suited to displaying large datasets with many visible features simultaneously. In addition, Mapbox GL's use of 3D vector graphic mapping instead of preset tiles made for a much more pleasing user experience, with smooth animations between zoom levels and better background processing during page loads. For these reasons, Mapbox GL was chosen as the base map for the remaining geographic visualizations.

\hypertarget{visualizing-non-geographic-data}{%
\subsection{Visualizing non-geographic data}\label{visualizing-non-geographic-data}}

There are hundreds of data visualization libraries available for the web which provide ways to produce charts and plots of varying complexity. The requirement of using open-source code narrows the field considerably.

After experimenting with several packages including D3, Raphael, Morris and others, the package Vega-Lite (\cite{Satyanarayan2016vega}) exhibited many of the characteristics desired. Notably, Vega-lite follows a ``grammar of graphics'' declarative syntax, as popularized by Wilkinson (\cite{Wilkinson2012grammar}), and this grammar allows concise description of the meaningful components of a graphic. An added benefit is that graphs and charts can be downloaded in image format or in Vega source format, which is helpful for other researchers wanting to learn how to use the data format themselves.

\hypertarget{dealing-with-large-datasets}{%
\subsection{Dealing with large datasets}\label{dealing-with-large-datasets}}

MATSim network files are usually small enough to fit in memory, but MATSim plan files and event files can be much larger than available memory, necessitating careful consideration about how to handle them.

Modern browsers allow access via API to a data storage area that is unique per hostname, e.g. \texttt{https://mysite.com} is allowed some storage on the local machine. Initial experiments revealed that each browser vendor implements this storage differently, with very strict limits on the absolute amount storage available, sometimes based on how much free space remains on the user's machine. It became apparent that this local browser-based storage would not be sufficient for MATSim outputs. A different approach is running a local file server process or application that would allow browser access to specific folders on the machine. This would be convenient for technically-minded advanced analysts, but violates the research goal of being fully web-based on the client end. Thus, a client-server paradigm emerges as the only truly viable alternative, and indeed this is how most websites operate today: the browser is the front-end to the heavier processing and storage tasks that happen on someone else's server. Note that ``someone else's server'' is usually referred to as ``the cloud''.

\hypertarget{mathub-platform-architecture}{%
\section{Platform architecture}\label{platform-architecture}}

A client/server architecture is chosen for this research based on the initial experiments described above.

Back-end server software managed file storage, user authentication, and data pre-processing. The front-end website communicates with these back-end servers to establish what resources a user has access to, and provides an application programming interface, or API, with which to query and fetch available files and resources. The code for those back-end servers is also open source.

The front-end architecture has several interacting components:

% ------------------------------------------------------
\hypertarget{mathub-build-system}{%
\subsection{Build system}\label{build-system}}

The build system of a modern web application is fairly complex and the JavaScript ecosystem changes rapidly. After numerous iterations, the current build system settled on a series of individual tools that all work together to produce the final assets that get sent to a user's browser. Those tools include the Vue command line interface (CLI), the NPM package manager, webpack, babel, and TypeScript. These are all common choices for a JavaScript-based build toolchain.

Notably, the initial codebase was migrated to the TypeScript language midway through development, as the benefits of a strongly-typed language were perceived to be worth the development time.\footnote{TypeScript is available at \url{https://typescript-lang.org}} TypeScript is a separate language from JavaScript but they are closely related. TypeScript nforces type annotations for variables and adds additional features such as enumerations. The TypeScript compiler then converts TypeScript code into valid ECMAScript 6 JavaScript, which can be run in the browser -- as browsers do not support TypeScript natively.

% ------------------------------------------------------
\hypertarget{vue-single-page-application}{%
\subsection{Vue Single Page Application}\label{vue-single-page-application}}

The primary framework used to build the application is known as ``Vue''\footnote{Vue framework, available at \url{https://vuejs.org}}. Vue is a framework for building interactive user interfaces on the web; essentially it provides the glue between the items a user clicks and the code that runs when they do so. Vue provides many services which allow a web page to behave more like a full-featured application, including routing between different URLs, state management, and componentization of code in a way that encourages code reuse and loose coupling. Vue depends on JavaScript, which means it does not work for users who have disabled running JavaScript in their browser.

Vue is most often used to write so-called ``single page applications'' which are websites that behave like desktop applications. Most large, popular websites such as GitHub, Twitter, and Facebook all employ this paradigm, meaning the site handles page transitions and URLs as if they are all in one common namespace, and the user thinks less about visiting URLs and more about navigation through visual components to accomplish tasks. This matches the research use case here precisely.

Vue components each encapsulate the three elements required for the modern web: HTML layout, JavaScript code, and CSS formatting. Components only interact with each other through well-defined pathways of properties and events, which greatly improves debuggability.

Note that Vue is just one of literally scores of web frameworks which all do essentially the same thing, providing interactivity to websites via JavaScript. Other frameworks such as React, Angular, and Svelte were considered but Vue was chosen due to its excellent documentation and support, and its nice ``middle ground'' between being lightweight and featureful.

% ------------------------------------------------------
\hypertarget{mathub-visualization-plug-ins}{%
\subsection{Visualization plug-ins}\label{visualization-plug-ins}}

Producing a system where new visualizations can be produced rapidly and added into the existing framework to generate new capabilities is one of the main goals of this research.

The Vue component architecture enables this. To create a new visualization, a developer copies an existing blank visualization template and gives it a new name, specifies the file inputs and parameters required, and then uses the above-described libraries to modify the code per their needs.

This currently requires coding skill in JavaScript; it is not a system that is point-and-click like an online data exploration tool. Experience with other similarly-designed platforms suggests that software-minded analysts or modelers would be able to extend the platform, but typical end users would not. Transport analysts are almost never JavaScript web programmers too; nor do they want to be. The existing set of MatHub features might be sufficient to meet the needs of regular users without them having to resort to coding extensions themselves.

% ------------------------------------------------------
\hypertarget{mathub-results-the-current-state-of-the-tool}{%
\section{Results: the current state of the tool}\label{results-the-current-state-of-the-tool}}

A working instance of the platform went live on the Internet in 2019.\footnote{Site was live at \url{https://viz.vsp.tu-berlin.de}, now defunct as of 2022} Sample datasets were uploaded, and pre-built visualizations were publicly accessible, as a demonstration of the platform's current state. A user login system was developed so that internal researchers could extend and experiment with the system, without exposing data or work-in-progress to the public.

Basic user, project, and file management capabilities were available. This included grouping files by tags or by model run identification codes.

Several types of aggregate visualizations were developed:

\begin{itemize}
\tightlist
\item
  Origin/destination flows between aggregate areas, so called ``spider
  diagrams''
\item
  Link flows, by time of day and mode
\item
  Transit supply explorer, which displays all transit routes and allows
  the user to see which routes serve specific stops and links.
\item
  Sankey diagrams, which can be used to depict changes/flows between
  between scenarios across multiple choices, such as shifts in mode
  between two scenarios (see Figure 3.1d)
\item
  Emissions levels on a geographic hexagonal grid basis
\end{itemize}

In addition, one disaggregate animation was available:

\begin{itemize}
\tightlist
\item
  A vehicle flow simulation, showing individual vehicle agents in
  real-time on the network.
\end{itemize}

See the set of screenshots in \autoref{fig:mathub-examples} for examples of the final state of the user interface. Unfortunately the tool is difficult to describe in screenshots, as the whole point of this research is to develop an interactive tool.

\begin{figure}
  \centering
	\begin{minipage}{1.0\textwidth}
  \includegraphics[width=\textwidth]{chapters/13-mathub/images/all-figures.png}
  \caption{MatHub sample visualizations, a - f. File management dashboard and examples of vehicle animations, transit and roadway volumes, and aggregate summary statistics are shown.}
  \label{fig:mathub-examples}
	\end{minipage}
\end{figure}

% ------------------------------------------------------
\hypertarget{mathub-workflow-feedback}{%
\subsection{Workflow feedback}\label{workflow-feedback}}

Initial prototypes of the tool did not meet the needs of test users. Problems included: difficult discerning which files were which; inability to efficiently use the model run tagging feature (in which a user could mark sets of files as belonging to a particular MATSim run); separate user logins causing data to be inaccesible to team members working on the same projects (resulting in everyone using a common ``team'' login, against best practices); private projects ``leaking'' onto the public website; and myriad usability bugs in the data visualizations themselves.

These usability problems were eventually solved by surveying other technical websites which organize and present large amounts of data. One website in particular, Github.com, was found to be well-liked by test users and has a similar hierarchical view of data: users can belong to organizations, and both organizations and users can create projects (``repositories'' on GitHub) which may large numbers of files.

By adopting a file, project, and user paradigm similar to that employed by GitHub, users were immediately more familiar and had less to learn. The site now adheres to this so closely that test users refer to the platform as ``MatHub''.

Longer term, however, further problems were noted. Most importantly, team members felt that the capabilities did not offer them visualizations beyond what they could create in other software packages. The promise of online dissemination of results was not compelling enough to justify the uploading of datasets to a separate visualization system. At least internally, analysts were most interested in publishing papers and producing high-quality image files for submission to journals. Without external-facing clients, the online functionality was merely nice to have, but not actually urgently necessary. As time went on into 2019 and 2020, the site was used less and less.

Internally this triggered some serious discussions about the viability, usefulness, and need of the platform. Given that this was just the first usable version, it seemed prudent to continue some further iteration on the platform to try and make it more usable and useful to internal users.

% ------------------------------------------------------
\hypertarget{mathub-performance}{%
\subsection{Performance}\label{performance}}

Even with modern hardware and the latest browsers, it is quite challenging to produce performant, visually pleasing results with disaggregate MATSim data. The vehicle flow simulation depends heavily on the back-end server to produce and deliver simulation ``frames'' to the browser in real-time, so that the browser simply has to render the data.

Various levels of aggregation make MATsim data much easier to visualize, as is reflected in the number of different visualizations this research was able to produce with aggregate data in a short time frame.

\textbf{Preprocessing.} The traffic animation and the emissions ``hex grid'' visualizations both rely on back-end server processes to preprocess the raw MATSim event outputs. This takes anywhere from a few seconds to many minutes, depending on the size of the simulation that is run. The preprocessing only needs to occur once, and thereafter the results are cached and stored on the server. The UI presents a helpful ``still processing'' message during this stage. Unfortunately, changing some settings such as the size of the hex-grids for the emission tool triggers time-consuming recalculations. Further work is being done to make these processes run as quickly as possible.

\textbf{Map layer limitations.} The Mapbox GL mapping library allows lines, points, and polygons to be displayed on top of (or interleaved with) a base map. There seems to be a number of map elements beyond which performance becomes very slow; various techniques can be used such as aggregating elements at further-out zoom levels to get around this. Another option is to only use Mapbox GL for the base map, and to use the WebGL graphics libraries to draw large numbers of elements directly on top of the map. This is the technique used for the traffic animation, which can easily support tens of thousands of elements (all in motion) simultaneously. For additional visualizations which have large numbers of graphical elements, more research will need to be done to layer WebGL elements on top of a base map.

\textbf{Challenging development.} As part of ``performance'' there was also a noticeable lag time for delivery of bug fixes and new features. Essentially, the client-server system turned out to be quite difficult to maintain. Multiple separate back end servers (production, staging, and development) needed to stay in sync with database schemas and front-end code features; for a small team, this proved quite onerous. The back end servers expected a very strict schema for data storage, which hamstrung the rapid prototyping and iteration of client side features. Basically, the team was found to be too small to keep things moving forward at a regular pace. This was not a problem in either the design of the server code or the features planned for the clients; but rather, an inability to keep the two in sync.

% ------------------------------------------------------
\hypertarget{mathub-mobile-device-support}{%
\subsection{Mobile device support}\label{mobile-device-support}}

Initially, the research targeted desktop browsers only. The reasoning was that analysts currently use desktop software, and it would be sufficient to complement those desktop tools with a new web-based option.

However, as the tool started becoming usable by internal users, it became apparent that everyone wanted some version of the visualizations to work on mobile devices, too. It was suggested that even a read-only visualization ``viewer'' for mobile would be better than not having the tool work at all on mobile.

To address this, the layout of the main user interface needed to be redesigned, but the overall stack of web-based libraries and components chosen was already well-suited to mobile use. This effort is currently underway.

% ------------------------------------------------------
\hypertarget{mathub-conclusions-and-outlook}{%
\section{Conclusions and outlook}\label{conclusions-and-outlook}}

Experimenting with the various technologies and getting all of the disparate pieces working together was an enormous task, one which took much longer than anticipated. However, those decisions are now made and the platform has become stable. \emph{Note however that as of 2022 this work and MatHub itself has been superseded; see \autoref{ch:simwrapper} for the tool that replaces it.}

A new visualization can generated by internal researchers in a matter of days or weeks. The researchers are certainly the most familiar with the inner workings of the system, but even so it has been encouraging to see new visualizations go from ideation to rough draft in relatively short order.

None of the above-listed visualizations are especially groundbreaking or visually stunning yet. All of them could be easily created using other tools, although usually without the nice interactivity that the web enables. This is a bit disappointing but the open nature of the platform, requiring no software installation by end users, still has an advantage: it opens up the display of MATSim results to the public and to decisionmakers, even if they do not have access to desktop mapping or travel forecasting software. And again, this is expected to just be the first step in further development of the platform.

Currently there is no common way to share MATSim datasets online. Another functionality gap that has emerged from these visualization experiments is a more regimented data management tool for MATSim. The combination of file storage and management capabilities along with the hierarchical project and folder user interface provides a natural place for users to store and disseminate results. But so far this has not materialized: users are comfortable with their existing file storage methods. Writing a data management system is not part of visualization research, and is likely too large a task to do ``on the side'' even if off-the-shelf components are leveraged. And even if it were built, users would have to then be conditioned to turn to and use this system instead of their existing workflows.

That is a friction already experienced by users with the MatHub approach. Perhaps this can be tackled in the future as MatHub and other approaches described in later chapters are further developed.

Finally, the world has not stood still while this platform was being developed. Just in the past two years, major data visualization efforts from well-funded companies such as Uber and others have been released. There are legitimate questions about how much of this work could be superseded by large, well-funded, professional coding teams. The slow pace of development of this client/server system foreshadowed some necessary changes to the roadmap for future work.

The MatHub visualization framework is operational and is now beginning to be useful for researchers. This bodes well for further development of many of the ideas embedded within MatHub.

All code is open and freely available on the MATSim Github site, available at \url{https://github.com/matsim-org/viz}.
